---
title: 爬取某网站小姐姐壁纸
tags:
- python
- 爬虫
- 壁纸
- 图片
copyright: true
comments: true
categories: Python案例
date: 2020-04-05 20:53:00
urlname: xiaojiejiebizhi
top_img: false
---

![封面](https://cdn.seovx.com/?mom=302)
<!-- less -->
<!-- more -->
# 介绍

>美桌壁纸小姐姐壁纸爬取

# 准备

* PYthon3.8（我用的是这个版本的）
* pycharm （其他的编辑器也可以）
* 模块：requests，parsel，os

# 思路

爬虫的思路
1. 分析目标网页，确定爬取的url路径，headers参数
2. 发送请求 -- requests 模拟浏览器发送请求，获取响应数据
3. 解析数据 -- parsel  转化为Selector对象，Selector对象具有xpath的方法，能够对转化的数据进行处理
4. 保存数据


# 步骤


## 第一步

确定爬取的url路径，headers参数
```python
base_url = 'http://www.win4000.com/mobile_2340_0_0_1.html'
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.87 Safari/537.36'}
```

User-Agent在浏览器的F12 Network里面获取（里面找到headers，在最下面就有你自己浏览器的User-Agent参数）


## 第二步

发送请求 -- requests 模拟浏览器发送请求，获取响应数据
```python
response = requests.get(base_url, headers=headers)
data = response.text
```


## 第三步

解析数据 -- parsel  转化为Selector对象，Selector对象具有xpath的方法，能够对转化的数据进行处理
```python
html_data = parsel.Selector(data)
data_list = html_data.xpath('//div[@class="Left_bar"]//ul/li/a/@href|//div[@class="Left_bar"]//ul/li/a/@title').extract()
```

使用列表推导式对列表进行分组
```python
data_list = [data_list[i:i + 2] for i in range(0, len(data_list), 2)]
```

创建图片的文件夹
```python
if not os.path.exists('img\\' + file_name):
    os.mkdir('img\\' + file_name)
print('正在下载：', file_name)
```

发送详情页的请求,解析出总页数
```python
response_2 = requests.get(html_url, headers=headers).text
html_2 = parsel.Selector(response_2)
page_num = html_2.xpath('//div[@class="ptitle"]//em/text()').extract_first()
```

## 最后

构建相册翻页的url地址，解析每一页的图片url地址，保存数据

```python
for url in range(1, int(page_num) + 1):
	url_list = html_url.split('.')
	all_url = url_list[0] + '.' + url_list[1] + '.' + url_list[2] + '_' + str(url) + '.' + url_list[3]
	response_3 = requests.get(all_url, headers=headers).text
	html_3 = parsel.Selector(response_3)
	img_url = html_3.xpath('//div[@class="pic-meinv"]//img/@src').extract_first()
	img_data = requests.get(img_url, headers=headers).content
	# 图片的文件名
	img_name = str(url) + '.jpg'
	# 保存数据
	with open('img\\{}\\'.format(file_name) + img_name, 'wb') as f:
		print('下载完成：', img_name)
		f.write(img_data)
```

# 完整代码

```python
import requests
import parsel
import os
base_url = 'http://www.win4000.com/mobile_2340_0_0_1.html'
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.87 Safari/537.36'}
response = requests.get(base_url, headers=headers)
data = response.text
html_data = parsel.Selector(data)
data_list = html_data.xpath('//div[@class="Left_bar"]//ul/li/a/@href|//div[@class="Left_bar"]//ul/li/a/@title').extract()
data_list = [data_list[i:i + 2] for i in range(0, len(data_list), 2)]
for alist in data_list:
    html_url = alist[0]
    file_name = alist[1]
    if not os.path.exists('img\\' + file_name):
        os.mkdir('img\\' + file_name)
    print('正在下载：', file_name)
    response_2 = requests.get(html_url, headers=headers).text
    html_2 = parsel.Selector(response_2)
    page_num = html_2.xpath('//div[@class="ptitle"]//em/text()').extract_first()
    for url in range(1, int(page_num) + 1):
        url_list = html_url.split('.')
        all_url = url_list[0] + '.' + url_list[1] + '.' + url_list[2] + '_' + str(url) + '.' + url_list[3]
        response_3 = requests.get(all_url, headers=headers).text
        html_3 = parsel.Selector(response_3)
        img_url = html_3.xpath('//div[@class="pic-meinv"]//img/@src').extract_first()
        img_data = requests.get(img_url, headers=headers).content
        img_name = str(url) + '.jpg'
        with open('img\\{}\\'.format(file_name) + img_name, 'wb') as f:
            print('下载完成：', img_name)
            f.write(img_data)
```

***

**快去试水吧，记得多准备几瓶营养快线(ಥ_ಥ)** 

说明：这个代码并不能爬取全站图片，详细的自己研究

****

**想要图片但懒得下载的走这边**-->__[转送门](https://www.lanzous.com/b0d7yfn6j)__
好像不是特别全上传的时候似乎漏掉了几个

***
偶然发现pyinstaller这个模块，这个模块可以把py程序封装成exe程序，在没有py环境的电脑上也可以运行
想要的同学可以直接下载，exe软件下载地址-->__[传送门](https://www.lanzous.com/b0d7ykpvg)__

![预览](https://cdn.seovx.com/?mom=302)